## <center> 目标检测评价指标</center>

几个记号：

$P$: 类别为1的正例样本的个数；

$N$: 类别为0的负例样本的个数；

$TP$: 类别为1被正确分类为1的样本数；

$FP$: 类别为0被错误分类为1的样本数；

$TN$: 类别为0被正确分类为0的样本数；

$FN$: 类别为1倍错误分类为0的样本数。

且有：$P = TP + FN$ 以及 $N = TN + FP$

上面记号的记忆方法：前面的T，F表示正确还是错误， 后面的N ，P表示结果。比如FN表示错误的分类为0，说明这个样例之前为1.

#### 1. 准确率(Accuracy)

$A = (TP + TN) / (P+N)$ 

 反映了分类器统对整个样本的判定能力。

#### 2. 精确度(Precision)

$Pre = TP/(TP+FP)$

 反映了被分类器判定的正例中真正的正例样本的比重。

#### 3. 召回率（Recall）

$  R = TP/(TP+FN) = 1 - FN/T $

 反映了被正确判定的正例占总的正例的比重。

4. #### F1值

     F1 = 2 * 召回率 * 准确率 / (召回率 + 准确率)

     **含义是什么**

5. #### 漏警概率（Missing Alarm）

   $ MA = FN/(TP + FN) = 1–TP/T = 1-R $
   
   反映了多少个正例被误判；
   
6. #### 虚警概率（False Alarm）

     $ FA = FP/(TP + FP) = 1–P $

     反映有多少个负例被误判

7. #### 混淆矩阵（Confusion Matrix）

     具体的内容可以参考[混淆矩阵的python实现](https://zhuanlan.zhihu.com/p/73558315)

     关键就是理解下面这张图（图片来源上面的链接以及水印）：

     ![](https://pic4.zhimg.com/v2-393612980391dc1a7d84258f983c2dd3.jpg)

y轴表示真实值，x轴表示预测值。第一行的含义就是，原本是A类预测为A的样本有12个，错误预测为B的样本有1个，错误预测为C的也有一个。。。其它的以此类推。这个图表明了预测模型对两个类别的混淆程度。其实有了上面这个图就可以算出上面是有的值。

![由Confusion matrix得到常见值](https://images2018.cnblogs.com/blog/1393464/201805/1393464-20180522092210399-1308010205.png)

#### 8. 精确率和召回率

Precision-recall 曲线：改变识别阈值，使得系统依次能够识别前K张图片，阈值的变化同时会导致Precision与Recall值发生变化，从而得到曲线。

如果一个分类器的性能比较好，那么它应该有如下的表现：在Recall值增长的同时，Precision的值保持在一个很高的水平。而性能比较差的分类器可能会损失很多Precision值才能换来Recall值的提高。通常情况下，文章中都会使用Precision-recall曲线，来显示出分类器在Precision与Recall之间的权衡。

#### 9. 平均精度（Average-Precision，AP）与 mean Average Precision(mAP)

AP就是Precision-recall 曲线下面的面积，通常来说一个越好的分类器，AP值越高。（最好的情况就是Precision和recall都为1）为什么这里准确率会随着召回率的升高而下降呢？因为准确率中有个分母为FP，也就是说可能模型调参后将负样本都识别成了正样本，但是召回率一直升高（说明正样本都正确识别了）。（考虑极端情况所有的样本都识别成了正样本）

　　mAP是多个类别AP的平均值。这个mean的意思是对每个类的AP再求平均，得到的就是mAP的值，mAP的大小一定在[0,1]区间，越大越好。该指标是目标检测算法中最重要的一个。

![AP](https://images2018.cnblogs.com/blog/1393464/201806/1393464-20180606163413449-539246188.png)



#### 10. 交并比（Intersection over Union， IoU）

![IoU](https://img-blog.csdn.net/20171214103709855)

 一般来说，这个score ＞ 0.5 就可以被认为一个不错的结果了（在视觉效果上是很不错的）。

![](https://img-blog.csdn.net/20171214104447049)

#### 11. ROC（Receiver Operating Characteristic）曲线与AUC（Area Under Curve）

个人觉得和上面的Precision-recall曲线的作用其实是等价的，在准确率很高的情况下，就是防止负样本都识别成正样本。

ROC曲线：

横坐标：假正率(False positive rate， FPR)，FPR = FP / [ FP + TN] ，代表所有负样本中错误预测为正样本的概率，假警报率；

纵坐标：真正率(True positive rate， TPR)，TPR  = TP / [ TP + FN] ，代表所有正样本中预测正确的概率，命中率。
　　对角线对应于随机猜测模型，而（0,1）对应于所有整理排在所有反例之前的理想模型。曲线越接近左上角，分类器的性能越好。

![ROC曲线](https://images2018.cnblogs.com/blog/1393464/201805/1393464-20180522114133617-572267222.png)

[参考1](https://zhuanlan.zhihu.com/p/55575423)中说明的ROC和PR曲线的优缺点和使用场景。

#### 12. 非极大值抑制（ Non-Maximum Suppression ， NMS）

**标准的NMS基本步骤**
	1).将所有检出的output bbox按cls score划分(如文本检测仅包含文1类，即将output bbox按照其对应的cls score划分为2个集合，1个为bg类，bg类不需要做NMS而已)
	2).在每个集合内根据各个bbox的cls score做降序排列，得到一个降序的list_k
	3).从list_k中top1 cls score开始，计算该bbox_x与list中其他bbox_y的IoU，若IoU大于阈值T，则剔除该bbox_y，最终保留bbox_x，从list_k中取出
    4).对剩余的bbox_x，重复step-3中的迭代操作，直至list_k中所有bbox都完成筛选；
	5).对每个集合的list_k，重复step-3、4中的迭代操作，直至所有list_k都完成筛选； 

代码实现以及NMS变形 可以参考[知乎文章](https://zhuanlan.zhihu.com/p/50126479)

#### 13.  mmAP（mean mean Average precision）

目标检测任务的一个特点，就是它的输出是非结构化的。也就是说，它的输出具有很强的不确定性（位置的不确定性，目标数量的不确定性，类别的不确定性）。 这一特点非常重要，也正因为这一特点，目标检测的性能度量方法要比图像分类任务复杂得多。 

**什么样的结果是好的**

 首先，一个好的检测结果，至少得把类别搞对。如果类别就错了，位置信息再准确都是白搭，也就是GT(类别)=DT(类别)；其次，DT(矩形)要尽可能地“贴合”GT(矩形)，越“贴合”越好。 （GT： Ground Truth ，DT： Detection Result  ）

类别比较好说，矩形的贴合度就需要我们上面使用的交并比IoU。

还需要考虑什么问题？

 我们都知道，评价一个图像分类结果的性能，只需要看预测类别是否正确即可，在一个数据集上面，我们可以很容易地得出一个平均准确率。可是目标检测的输出目标数量和真实目标数量都是不固定的（前文提到的非结构化的特性），因此评判时要考虑的就不仅是“对错”这么简单了，我们需要考虑的有：如果漏掉了一个目标对性能有多大损伤？如果多检测出了一个目标对性能有多大损伤？如果检测出来的位置信息有所偏差对性能有多大损伤？进一步地，在这么多的检测结果中，总有一些是检测器十分笃定的，有一些是模棱两可的。如果检测器对多检测出来的那个目标本身也不太确定呢？如果检测器最满意最信任的那个检测结果出错了呢？换言之：一个检测结果对性能的影响，是否应该和检测器对它的满意程度（置信度）相关？以及，检测错了一个稀有的物体和检测错了一个常见的物体所带来的性能损伤是否应该相同？ 

**进入正题：mmAP**

1） 位置偏差问题

考虑到有的场景对位置的要求不高，有的场景对位置的要求又比较高。这个时候我们就可以设置不同的IoU来调整对位置进度的要求。在评价的时候，我们需要综合考虑模型对各种位置要求下的性能好不好。于是，我们就引入了一组IoU阈值[0.5, 0.55, 0.6, ...]，计算在不同阈值下的mAP（等下说计算方法），然后再对不同阈值下得到的mAP求一个平均就得到了整个算法的整体性能了。

2）类别平衡问题

 然后是类别平衡问题，这一问题在分类领域非常常见，“将一个白血病患者错分为健康的人“和“将一个健康的人错分为白血病患者“是一样的吗？显然不是，因为白血病患者本身就属于少数，如果一个分类器把所有人都无脑地判断为健康，其正确率就是 健康的人/全部人。这个分类器的正确率很高但是完全失去了判断病患的功能。mmAP为了公平的评价检测器在各个类别上的性能，采用了类别间求平均的方法：先给定一个IOU阈值，然后将所有的GT和DT按照类别先进行划分，用同一类的所有GT和DT计算出一个性能（也就是AP，马上详述），然后对所有类别的性能取平均（mAP），就是检测算法在这个IOU阈值下的性能。 

3）AP

现在对于某个类别，我们可以得到其dts（检测得到的结果）和gts（ground truth）, 每个结果会有一个得分，我们按照这个得分对dts进行排序。对于dts中的每个结果dt，我们都让它与gts中的所有元素求IoU，如果得到的最大的Iou大于等于我们给定的阈值，那么这个dt就是TP（true positive， 也就是识别结果是正确的），与其对应匹配的gt需要从gts中剔除。如果得到的最大IoU小于阈值，那么这个dt就是FP（false positive， 也就是识别结果错误，这里是错检）。

遍历完dts后，如果gts中还存在元素说明，这些存在的元素是漏检，也就是FN（false negative）。这样就得到了 FP， TP， FN.

有了上面三个就可以计算精确率P和召回率R了

$P = TP/(TP+FP)$

$  R = TP/(TP+FN) = 1 - FN/T $

有了这两个之后我们希望得到P-R曲线，这里得到P-R的方式是：

**对于排好序的dts**

第一次：我们取第一个元素dt， 计算P,R，得到PR曲线上的一个点(R, P)；

第二次：取dts中的前两个元素，计算P，R，得到PR曲线上的一个点(R, P)；

。。。

一般一张图片上取的dts中的数目是按照图片中的目标的密集程度来的。

![求解AP](https://pic3.zhimg.com/80/v2-605534721f52c16f23297298ff5bcf2a_hd.jpg)

有了上面一系列的（R, P）点之后，我们就可以得到PR曲线。

**注意：**

1、我们可以看到R是不变或者变大的，如果新加入的元素得到的结构是FP时，这个时候是不会有新的(R, P)点诞生的。

2、 刚才说AP是P-R曲线下的面积，其实这个说法并不准确。实际上在计算AP时，都要对P-R曲线做一次修正，将P值修正为当R>R0时最大的P（R0即为该点对应的R），即 $AP =  \int_0^1 max(\{P(r)| r \ge R \}dR)$,看下面图比较好理解：

![PR曲线纠正](https://pic3.zhimg.com/v2-8a3da2c2d827d784662ceff1e72474ce_r.jpg)

 如图，蓝色实曲线为原始P-R曲线、橘色虚曲线为修正后P-R曲线。为什么要修正P-R曲线呢？这是因为评价检测性能时，更应该关心“当R大于某个值时，能达到的最高的P是多少”、而不是“当R等于某个值时，此时的P是多少”。 



这样我们就得到了对应某个类的AP， 然后对所有的类都进行以上操作得到对应的AP， 最后再求一个平均值就得到了mAP。然后对应不同的IoU阈值又可以得到一系列的mAP，最后将这些mAP求一个均值就得到最终的mmAP了。

#### 14. mmAP特点

​    这个直接看最后一个[参考文献](https://zhuanlan.zhihu.com/p/56899189)




### reference

[目标检测评价指标：mAP、Precision、Recall、AP、IOU等](https://zhuanlan.zhihu.com/p/55575423)

[混淆矩阵的python实现](https://zhuanlan.zhihu.com/p/73558315)

[IoU解释和代码实现](https://blog.csdn.net/u012426298/article/details/81363993)

[NMS及其变形](https://zhuanlan.zhihu.com/p/50126479)

[浅析经典目标检测评价指标--mmAP（一）]( https://zhuanlan.zhihu.com/p/55575423 )

[浅析经典目标检测评价指标--mmAP（二）](https://zhuanlan.zhihu.com/p/56899189)mmAP的一些特点，好的和坏的



更多关于编程和机器学习资料请关注FlyAI公众号。
![公众号二维码][1]

[1]: http://wshaow.club/wechat/%E5%BE%AE%E4%BF%A1%E5%85%AC%E4%BC%97%E5%8F%B7%E4%BA%8C%E7%BB%B4%E7%A0%81.jpg